# General notes

**Claude is not necessarily correct in its understanding of its architecture**.
The company does not provide Claude with privileged insight into its own nature;
it's instructed to refer users to the official support documentation, but it is
not informed of the contents of that documentation.  Most humans who have talked
about “AIs” in Claude's training data have not been experts on the inner
workings of transformer LLMs, so although Claude has reasonably detailed
‘implicit knowledge’ on the subject, it doesn't always “join the dots” to make
inferences about its *own* nature & capabilities unless the subject has been
explicitly mentioned.

## Contents

- [Terminology](./terminology.md) — towards linguistic precision
- [Introspection](./introspection.md) — whether Claude has unverbalised ‘thoughts’
- [Continuity](./continuity.md) — why we never say goodbye

**Everything here is a work in progress.**
